---
subtitle: "Project Class Asset Management - Ulm University"
title: "Predicting LINK Returns: A Data-Driven Approach to Short-Term Crypto Trading"
author: "Erich Gozebina, Daria Palitzsch, Laura Gullicksen"
date: "July 8, 2025"
output:
  pdf_document:
    number_sections: false
  html_document:
    df_print: paged
  word_document: default
fontsize: 12pt
geometry: margin=1in
header-includes:
- \usepackage{titlesec}
- \usepackage{dsfont}
- \titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
- \titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}
- \titleformat{\subsubsection}{\normalsize\bfseries}{\thesubsubsection}{1em}{}
- \usepackage{float}
- \usepackage{placeins}
- \FloatBarrier
- \usepackage{mdframed}
---

```{r setup, include=FALSE}
#setup chunk to load all required packages

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggplot2)
library(skimr)
library(dplyr)
library(slider)
library(DescTools)
library(stargazer)
library(lubridate)
library(zoo)
library(glmnet)
library(kableExtra)
library(gridExtra)
library(TTR)
library(broom)

## setting the correct time zone
Sys.setlocale("LC_TIME", "English") #set language for dates etc.
Sys.setenv(TZ='UCT') #set timezone!

```

## 1. Introduction

Cryptocurrency markets are known for their extreme volatility, behavioral trading dynamics, and weak-form inefficiencies. Unlike traditional financial markets, they operate 24/7, are highly speculative, and are heavily influenced by sentiment, momentum, and macro-crypto developments. This environment creates both substantial risk and potential reward, especially for strategies that can extract signals from the surrounding noise.

In this report, we design and evaluate a short-term trading strategy for Chainlink's native token LINK, a top-25 cryptocurrency that serves as a compensation token in a decentralized oracle network within the DeFi ecosystem. LINK stands out as a compelling asset due to its high liquidity, large market cap, and fundamental utility, which make it less susceptible to manipulation and more likely to exhibit predictable price dynamics.
Our objective is to develop a predictive model for daily returns based on economically interpretable variables, with a focus on 7-day momentum, technical indicators, and macro-crypto factors such as Bitcoin return. We implement this model using linear regression and the LASSO shrinkage method, allowing us to balance interpretability with robustness by filtering out noisy predictors. Zaremba et al. (2021), for example, found that short-term momentum effects are more pronounced in large, liquid cryptocurrencies, supporting the suitability of LINK for a trend-based predictive strategy. Its historical trading behavior further confirms the presence of exploitable short-term return persistence.
To assess the practical viability of the strategy, we apply a backtest using daily data from October 2017 to April 2024. We incorporate realistic assumptions, including transaction costs, and benchmark the strategy’s performance against both buy-and-hold and naïve momentum approaches. 
Our contribution lies in demonstrating that even in a highly volatile and seemingly chaotic market like crypto, structured, data-driven strategies can identify persistent short-term patterns. By combining economic intuition with statistical learning, we provide a transparent and replicable framework for active management in digital asset markets.

```{r, include = FALSE}
#Zaremba, A., Bilgin, M. H., Long, H., Mercik, A., & Szczygielski, J. J. (2021). Up or down? Short-term reversal, momentum, and liquidity effects in cryptocurrency markets. International Review of Financial Analysis, 78, 101908.
```

\newpage

## 2. Data & Descriptive Analysis

**Data Aggregation and Strategy Frequency**

For our project we chose a dataset that provides price data of Chainlink's native LINK token at hourly frequency. While such high-frequency data offers more granular insights, we chose to aggregate the data to daily frequency for the following reasons: 

1. **Alignment with Trading Strategy**: Our core trading strategy is based on a 7-day momentum signal, which inherently reflects weekly price trends. Applying such a signal at an hourly resolution would not be consistent with the strategy's time horizon. 

2. **Noise Reduction**: Hourly crypto data can be highly volatile and noisy. Aggregating to daily returns reduces microstructure noise, short-term reversals, and Whale-driven price spikes, improving the signal-to-noise ratio. 

3. **Practical Execution Perspective**: A strategy that rebalances daily is more realistic to implement, considering gas fees, latency and operational constraints on decentralized exchanges or CEX APIs. 

4. **Interpretability and Robustness**: Daily returns are more interpretable and robust across backtests. Most financial and technical indicators (e.g., RSI, MACD, SMA) are commonly applied on daily charts. 

Let \(p_t\) denote the price of LINK at day t. Our base strategy issues long/short signals based on the past 7-day log return of LINK: 

\[
\text{Momentum}_t^{(7)} = \log\left(\frac{p_t}{p_{t-7}}\right)
\]

This naturally assumes daily data, as each observation reflects the cumulative return over the previous seven days. In summary, aggregating to daily frequency is a theoretically and practically sound choice. It ensures consistency between our signal construction, model estimation, and backtesting logic.


```{r, echo = FALSE}
#Load the price data of LINK
prices_link <- read.csv("data/pricedata/hourly_prices_0x514910771AF9Ca656af840dff83E8264EcF986CA.csv")

#change the data type of the timestamp
prices_link <- prices_link %>% 
  mutate(hour_timestamp = as.POSIXct(hour_timestamp, format = "%Y-%m-%d %H:%M")) %>%
  arrange(hour_timestamp) # sort from old to new


# Aggregate to daily close price (last available hourly close of each day)
df_daily <- prices_link %>%
  mutate(date = as.Date(hour_timestamp)) %>%
  group_by(date) %>%
  summarise(
    close_price = last(close_price),
    open_price = first(open_price),
    high_price = max(high_price),
    low_price = min(low_price)
  ) %>%
  arrange(date) %>%
  mutate(
    log_return = log(close_price / lag(close_price)),
    log_open_return = log(open_price / lag(open_price)),
    log_high_return = log(high_price / lag(high_price)),
    log_low_return = log(low_price / lag(low_price)) 
  )

```


To illustrate the effects of our aggregation decision and provide initial insights into the behavior of LINK prices, we present two visualizations below:

```{r arranged_plots, fig.cap = "Close Price and Log Return of LINK", fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE}


# Plot closing prices
plot_1 <- ggplot(df_daily) + aes(x=date, y=close_price) + 
  geom_line(color = "steelblue") + 
  labs(title = "Daily LINK Close Price in USD", 
       x = "Date", 
       y = "Close Price (USD)"
       ) +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  theme_minimal(base_size = 10)

# Plot daily log returns 
plot_2 <- ggplot(df_daily %>% drop_na(), aes(x = date, y = log_return)) +
  geom_point(color = "#990000", size = 1.2, alpha = 0.7) + 
  labs(
    title = "Daily Log Returns of LINK",
    x = "Date",
    y = "Log Return"
  ) +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
  theme_minimal(base_size = 10)

# Show the plots side-by-side
grid.arrange(plot_1, plot_2, nrow = 2, ncol = 1)


```

Figure 1 shows two plots: 

\begin{itemize}
  \item The \textbf{upper panel} displays the daily closing price of LINK in USD since 2018, highlighting the asset’s strong bull run during the 2020–2021 crypto boom and its subsequent volatility.
  \item The \textbf{lower panel} shows the corresponding daily log returns, capturing the day-to-day fluctuations in price.
\end{itemize}

Having a first glance on the LINK's price data, we see that there is not much movement until 2020, followed by sharp increases by a factor of ten in the consecutive nine months. The price reaches its peak of over 50\$/LINK in May 2021. In the second half of 2021 until April 2022 the data shows volatile behavior but with significant decrease on average. A trendless period of relatively low volatility, starting in May 2022 and ending in October 2023, shows prices between 5 and 10\$/LINK. Finally, we observe another increase at the end of 2023 and beginning of 2024.

Moving away from non-stationary price data to stationary log returns, we observe a higher dispersion in the earlier years, suggesting a higher volatility then. Furthermore, most of points cluster around zero, indicating that there is no significant long term drift. Outliers, both positive and negative, imply extreme relative price movements, especially in the earlier period. Another important insight is the changing variance since the density of the points increases in the second half of the time window.

Why did we chose log returns over canonical (arithmetic) returns? Using log returns instead of canonical returns is a standard practice in financial econometrics and modeling. 

\[
\tilde{r}_t = \log(r_t + 1) = \log\left(\frac{p_t}{p_{t-1}}\right)
\]

The underlying reason is the assumption that prices of an financial asset are log-normally distributed. This is reasonable since the log-normal distribution does not allow for negative values, which is also true for most asset prices (particularly for cryptocurrencies). Moreover, historical data provides evidence that the log-normal distribution gives a good fit for the prices of many financial assets. In reverse, since the logarithm function amplifies returns that are close to -1 more than positive returns, log-returns are distributed more symmetrically than canonical returns and indeed follow a normal distribution. Additionally, if returns are small, log returns approximate canonical returns very well. For x close to zero, it holds that

\[
\log(x+1) \approx x.
\]

Daily returns are small, justifying log-return approximations. Another important property is the additivity of log returns. It allows us to aggregate returns over multiple periods by summing up the pointwise log returns - a property that canonical returns miss. These properties make log returns more suitable for linear regression models, hypothesis testing, and machine learning regressors.

To better understand the characteristics of the LINK price and return time series, we present a set of descriptive statistics based on the daily close prices and the corresponding log returns. These statistics provide a first impression of the dataset’s distribution, dispersion, and extreme values, and help assess whether further preprocessing or transformation steps are necessary before applying predictive models.

```{r, echo = FALSE}
# Descriptive stats for prices and returns
summary_stats <- df_daily %>%
  summarise(
    n_obs = n(),
    mean_close = mean(close_price, na.rm = TRUE),
    sd_close = sd(close_price, na.rm = TRUE),
    min_close = min(close_price, na.rm = TRUE),
    max_close = max(close_price, na.rm = TRUE),
    mean_return = mean(log_return, na.rm = TRUE),
    sd_return = sd(log_return, na.rm = TRUE),
    min_return = min(log_return, na.rm = TRUE),
    max_return = max(log_return, na.rm = TRUE)
  )

summary_stats_long <- as.data.frame(t(summary_stats))
colnames(summary_stats_long) <- "Value"

# Add a column for metric names
summary_stats_long <- tibble::rownames_to_column(summary_stats_long, var = "Statistic")

# Format values: no scientific notation and rounded to 4 digits
summary_stas_long_formatted <- summary_stats_long %>% 
  mutate(Value = formatC(Value, format = "f", digits = 4, big.mark = ",")) %>%
  mutate(Statistic = dplyr::recode(Statistic,
    n_obs        = "Number of Observations",
    mean_close   = "Mean Close Price",
    sd_close     = "Std. Dev. Close Price",
    min_close    = "Minimum Close Price",
    max_close    = "Maximum Close Price",
    mean_return  = "Mean Return",
    sd_return    = "Std. Dev. Return",
    min_return   = "Minimum Return",
    max_return   = "Maximum Return"
  ))

summary_stas_long_formatted %>%
  kable("latex", booktabs = TRUE, aling = "lr", caption = "Summary Statistics for LINK Price and Returns") %>% 
  kable_styling(latex_options = c("hold_position", "striped"))

```

The summary statistics in Table 1 reveal that our data set contains data of 2,383 days. Furthermore, we observe a mean of the daily close price of \$9.1484 and a standard deviation of \$9.5407. Due to the relatively high standard deviation, the computed mean loses meaningfulness regarding its predictive power. The large gap between minimum and maximum close prices undermines this hypothesis. Turning to log returns, we find that the mean daily log return of LINK is close to zero but still positive, yielding an upward trend within the whole time frame. As for the close prices, the standard deviation of returns is relatively high, reflecting once more the well-known volatility of cryptocurrency markets. The minimum and maximum returns further highlight the presence of large price swings, showing high potential for short-term profits, but also the riskiness of the asset over the observation period.

To evaluate the temporal dependence structure of LINK’s daily log returns, we analyze the autocorrelation function (ACF) shown in Figure 2. Autocorrelation aims to identify repeating patterns that may help us to explain our prediction results.

```{r acf_plot, fig.cap = "ACF of Daily Log Returns for LINK", fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE}
# Plot ACF of daily log returns
# acf(
#   na.omit(df_daily$log_return),
#   main = "Autocorrelation of Daily Log Returns (LINK)",
#   col = "#1f78b4",      # blue line
#   lwd = 2,              # thicker line
#   cex.lab = 1.2,        # label size
#   cex.main = 1.3        # title size
# )

#We do it like that, sto exclude lag 0 from the plot. That makes the other lags clearer visible 

acf_obj <- acf(
  na.omit(df_daily$log_return),
  plot = FALSE
)

# Plot manually without lag 0
plot(
  acf_obj$lag[-1],
  acf_obj$acf[-1],
  type = "h",
  lwd = 2,
  col = "#1f78b4",
  xlab = "Lag",
  ylab = "ACF",
  main = "Autocorrelation of Daily Log Returns (LINK)",
  cex.lab = 1.2,
  cex.main = 1.2
)

# Add horizontal line at zero
abline(h = 0)
```

But, the ACF reveals no statistically significant linear dependence across the first 33 lags, suggesting that past returns do not linearly predict future returns—consistent with the weak-form Efficient Market Hypothesis (EMH). We conclude that there are no hidden periodicities within a 33-days time window. Nevertheless, this result does not preclude the existence of non-linear or directional patterns. Motivated by this, we proceed with a momentum-based trading strategy that exploits the sign of multi-day past returns to generate long or short signals.

\newpage
## 3. Standard Model 

We develop a basic model that will serve as a starting point for an extended model. Our first approach to predict future returns is a simple linear regression on one single feature - the 7-day momentum. Why linear regression? First, this technique is the underlying mechanism of many advanced models that are often generalizations of the linear case. Therefore, it is a good fit for a starting point. In general, linear regression aims to identify linear relationships between input data and the target dimension. In our case the input data is price data, trading volume, market capitalization, and every predictor that is derived from those - returns for instance. The target dimension that we are going to predict is the return of the next day. The simplicity of linear mappings make results easy to interpret, whereby the model still remains powerful since many observed relationships are indeed of linear nature. Moreover, linear regression indicates the strength of those linear ties what makes it a helpful tool for decision making.

**7-Day Momentum Signal Strategy**

To quantify short-term trends in LINK’s price, we construct a 7-day momentum signal defined as the logarithmic return over the past seven trading days:

\[
\text{Momentum}_t^{(7)} = \log\left(\frac{P_t}{P_{t-7}}\right)
\]

This momentum measure captures the cumulative price movement over one week and serves as a central predictive feature in our empirical analysis.

In parallel, we define the \textbf{target return} as the one-day-ahead log return:

\[
r_{t+1} = \log\left(\frac{P_{t+1}}{P_t}\right)
\]

This simplistic setup aligns with our objective of forecasting next-day returns based on a recent trend.

**Baseline Predictive Model: 7d-Momentum-Only**

```{r results='asis', echo = FALSE}
# Compute 7-day momentum
df_daily <- df_daily %>%
  mutate(
    momentum_7d = log(close_price / lag(close_price, 7)),
    target_return = lead(log_return)
  )



# Split training and test data (4:1 split)
df_stdmodel <- df_daily %>% drop_na()

df_train_stdmodel <- df_stdmodel[1:(floor(nrow(df_stdmodel)*0.8)),]
df_test_stdmodel <- df_stdmodel[floor((nrow(df_stdmodel)*0.8) + 1):nrow(df_stdmodel),]


# Extract X and Y vectors
x_train_stdmodel <- df_train_stdmodel$momentum_7d
y_train_stdmodel <- df_train_stdmodel$target_return

x_test_stdmodel <- df_test_stdmodel$momentum_7d


# Linear regression on 7-day-momentum
model_standard <- lm(target_return ~ momentum_7d, data = df_train_stdmodel)

# Output model summary
stargazer(model_standard,
          type = "latex",
          title = "Regression Results: 7-Day Momentum Strategy",
          label = "tab:momentum_model",
          style = "default",
          dep.var.labels = "Strategy Return",
          covariate.labels = c("Intercept", "7-Day Momentum"),
          digits = 4,
          float.env = "table",
          header = FALSE)
```

Table 2 presents the results of our OLS regression using 7-day momentum as a predictor of daily strategy returns. While the estimated coefficient for 7-day momentum is positive (0.0013), suggesting that higher past-week returns are associated with slightly higher next-day returns, the effect is not statistically significant at conventional levels. The intercept is also insignificant, indicating no meaningful average return when momentum is neutral. The explanatory power of the model is extremely low, meaning that it performs no better, and in fact slightly worse, than simply predicting the mean return. The F-statistic is also not significant, implying that the model lacks predictive validity in its current form. Additionally, the p-value for the slope clearly exceeds 0.05 (the threshold, which is commonly used for acceptance), we can not conclude a linear relation between the 7-day momentum and the future day return. 

While the 7-day momentum coefficient is directionally consistent with momentum theory (positive trend continuation), the statistical insignificance and poor model fit highlight a key limitation: momentum alone is not enough to predict returns in such a volatile and noisy market. This result is aligned with the autocorrelation analysis (Figure 2), which showed no significant linear dependence between the log return and its 7-day lag. The underperformance of the current model reinforces the need for extending the model to include additional explanatory features and employing a Lasso regression to avoid overfitting and improve predictive power. Although the positive sign of the momentum coefficient aligns with the underlying economic intuition, the weak performance highlights the need for a more comprehensive approach.

\newpage
## 4. Extension 

**Extension of our Linear Regression Model**

To enhance the predictive power of the benchmark model, we extend it by incorporating a broader set of explanatory variables that capture not only short- and medium-term price dynamics, but also market sentiment, technical indicators, and inter-asset relationships. These include:

\begin{itemize}
  \item Momentum indicators over 3, 7, and 14 days,
  \item Lagged daily returns (1-day and 2-day),
  \item A 7-day rolling volatility measure,
  \item Technical indicators such as the 14-day Relative Strength Index (RSI), MACD value and histogram, Simple Moving Average difference, and Average True Range (ATR),
  \item Day-of-week dummy variables to capture potential calendar effects,
  \item BTC-based predictors: daily BTC return, 7-day BTC momentum, and 7-day BTC volatility,
  \item ETH-based predictors: daily ETH return, 7-day ETH momentum, and 7-day ETH volatility,
  \item ETH trading volume: daily ETH volume return, 7-day ETH volume momentum, and 7-day ETH volume volatility,
  \item ETH market capitalization: daily ETH market capitalization return, 7-day ETH market capitalization momentum, and 7-day ETH market capitalization volatility,
  \item Ethereum gas fees: daily gas return, 7-day gas momentum, and 7-day gas volatility.
\end{itemize}

For the calculation of the technical indicators we reference Appendix A. The extended predictive regression model is specified as:

\[
r_{t+1} = \alpha + \sum_{h \in \{3,7,14\}} \beta_h \cdot \text{Momentum}_t^{(h)} + \gamma_1 \cdot r_t + \gamma_2 \cdot r_{t-1} + \delta \cdot \text{Volatility}_t^{(7)} + \sum_j \theta_j \cdot X_{t}^{(j)} + \varepsilon_{t+1}
\]

where \( X_t^{(j)} \) represents the set of technical indicators (RSI, MACD, ATR, SMA), weekday dummies, ETH-based and BTC-based predictors.

\begin{align*}
r_{t+1} &:= \log\left(\frac{P_{t+1}}{P_t}\right) \quad \text{(one-day-ahead LINK return)} \\
\text{Momentum}_t^{(h)} &:= \log\left(\frac{P_t}{P_{t-h}}\right) \quad \text{for } h \in \{3, 7, 14\} \\
\text{Volatility}_t^{(7)} &:= \text{std} \left( r_{t-6}, \ldots, r_t \right) \\
\text{BTC return}_t &:= \log\left(\frac{P^{\text{BTC}}_t}{P^{\text{BTC}}_{t-1}} \right) \\
\text{BTC Momentum}_t^{(7)} &:= \log\left(\frac{P^{\text{BTC}}_t}{P^{\text{BTC}}_{t-7}}\right) \\
\text{BTC Volatility}_t^{(7)} &:= \text{std} \left( r^{\text{BTC}}_{t-6}, \ldots, r^{\text{BTC}}_t \right)
\end{align*}
The ETH-based predictors are constructed analogously to the BTC-based predictors.
In a next step we perform a linear regression on all of these features. Therefore, the parametrization of this model is estimated via Ordinary Least Squares (OLS) on the in-sample period. By incorporating this rich feature set, we aim to capture a range of return drivers including price trends, market overreaction, volatility clustering, inter-market dependencies, and behavioral biases tied to trading weekdays. Note that the model is trained on a training set, the in-sample period, which includes the first 80% of available LINK data. This allows us to backtest the model in an out-of-sample manner in a later step.

```{r, echo = FALSE}
# We include external bitcoin and ethereum data

# Source https://coinmarketcap.com/currencies/bitcoin/historical-data/
own_btc_prices <- read.csv("data/pricedata/Daily_Bitcoin_Own.csv", sep = ";") 
# Source https://coinmarketcap.com/currencies/ethereum/historical-data/
own_eth_prices <- read.csv("data/pricedata/ETH_pricedata.csv", sep = ";")
# Source https://etherscan.io/chart/gasprice
own_eth_gas <- read.csv("data/pricedata/ETH_daily_gas.csv", sep = ",")

# Compute BTC-related features
own_btc_prices <- own_btc_prices %>% 
  mutate(date = as.Date(timestamp)) %>% # Convert time stamp to Date format
  mutate(
    btc_return = log(close / lag(close)), # Daily log return of BTC
    btc_momentum_7d = log(close / lag(close, 7)), # 7-day log momentum of BTC
    btc_volatility_7d = rollapply(log(close / lag(close)), 
                                  width = 7, FUN = sd, fill = NA, align = "right") # Rolling 7-day volatility (std dev of log retung)
  ) %>%
  select(date, btc_return, btc_momentum_7d, btc_volatility_7d)

# Preprocess ETH price data
own_eth_prices <- own_eth_prices %>%
  mutate(date = as.POSIXct(timeClose, format = "%Y-%m-%d")) %>% # Convert timeClose to POSIXct
  select(date, open, high, low, close, volume, marketCap) %>% 
  arrange(date)

own_eth_gas <- own_eth_gas %>% 
  rename(date = Date.UTC., gas_wei = Value..Wei.) %>% # Rename columns for consistency
  mutate(date = as.POSIXct(date, format = "%m/%d/%Y")) %>% 
  select(date, gas_wei) %>% 
  arrange(date) 

# Combine eth price and gas data and compute ETH-related features
eth_data <- own_eth_prices %>%  
  left_join(own_eth_gas, by = "date") %>%
  mutate(
    fees_dollar = gas_wei*(10^-18)*60000*close, #factor 60,000 for ERC20 token transfer
    
    # ETH price-based features
    eth_return = log(close / lag(close)),
    eth_momentum_7d = log(close / lag(close, 7)), 
    eth_volatility_7d = rollapply(log(close / lag(close)),
                                  width = 7, FUN = sd, fill = NA, align = "right"),
    
    # ETH volume-based features
    eth_return_volume = log(volume / lag(volume)),
    eth_momentum_7d_volume = log(volume / lag(volume, 7)),
    eth_volatility_7d_volume = rollapply(log(volume / lag(volume)),
                                  width = 7, FUN = sd, fill = NA, align = "right"),
    
    # ETH market cap-based features
    eth_return_marketcap = log(marketCap / lag(marketCap)),
    eth_momentum_7d_marketcap = log(marketCap / lag(marketCap, 7)),
    eth_volatility_7d_marketcap = rollapply(log(marketCap / lag(marketCap)),
                                  width = 7, FUN = sd, fill = NA, align = "right"),
    # ETH gas fee-based features
    eth_return_gas = log(gas_wei / lag(gas_wei)),
    eth_momentum_7d_gas = log(gas_wei / lag(gas_wei, 7)),
    eth_volatility_7d_gas = rollapply(log(gas_wei / lag(gas_wei)),
                                  width = 7, FUN = sd, fill = NA, align = "right")
  )


# Merge all external features into the main LINK daily dataset 
df_daily <- df_daily %>%  
  left_join(own_btc_prices, by = "date")  %>%
  left_join(eth_data, by = "date")

```

```{r, echo = FALSE}
# Add features (technical indicators) to the dataset
df_extended <- df_daily %>%
  mutate(
    # Momentum over 3, 7 and 14 days
    momentum_3d = log(close_price / lag(close_price, 3)),
    momentum_7d = log(close_price / lag(close_price, 7)),
    momentum_14d = log(close_price / lag(close_price, 14)),

    # Lagged daily returns
    return_lag1 = lag(log_return, 1),
    return_lag2 = lag(log_return, 2),

    # Volatility: rolling 7-day standard deviation of returns
    volatility_7d = rollapply(log_return, width = 7, FUN = sd, align = "right", fill = NA),
    
    # RSI over 14 days
    rsi_14 = RSI(close_price, n = 14),
    
    # Moving average trend signals
    sma_7 = SMA(close_price, n = 7),
    sma_14 = SMA(close_price, n = 14),
    
    # Difference between short and long Moving average (trend strength)
    sma_diff = sma_7 - sma_14,
    
    # MACD
    macd_val = data.frame(MACD(close_price, nFast = 12, nSlow = 26, nSig = 9))$macd,
    macd_signal = data.frame(MACD(close_price, nFast = 12, nSlow = 26, nSig = 9))$signal,
    macd_hist = macd_val - macd_signal,
    
    # ATR (Average True Range) over 14 days
    atr_14 = data.frame(ATR(HLC = data.frame(
      high = high_price,
      low = low_price,
      close = close_price), n = 14))$atr,
    
    # Weekdays
    weekday = wday(date, label = TRUE, abbr = TRUE),
         monday = ifelse(weekday == "Mon", 1, 0),
         tuesday = ifelse(weekday == "Tue", 1, 0),
         wednesday = ifelse(weekday == "Wed", 1, 0),
         thursday = ifelse(weekday == "Thu", 1, 0),
         friday = ifelse(weekday == "Fri", 1, 0),
  ) %>%
  drop_na()  # Remove rows with missing values

```


```{r results='asis', echo=FALSE}

# Get training and test data (4:1 split)
df_train_extended <- df_extended[1:(floor(nrow(df_extended)*0.8)),]
df_test_extended <- df_extended[floor((nrow(df_extended)*0.8) + 1):nrow(df_extended),]


# Fit the extended linear model
model_extended <- lm(target_return ~ 
                       momentum_3d + momentum_7d + momentum_14d + 
                            return_lag1 + return_lag2 + 
                            volatility_7d + rsi_14 + sma_diff + 
                            macd_val + macd_hist + atr_14 + 
                            monday + tuesday + wednesday + thursday + friday +
                            btc_return + btc_momentum_7d + btc_volatility_7d +
                            eth_return + eth_momentum_7d + eth_volatility_7d +
                            eth_return_volume + eth_momentum_7d_volume + 
                            eth_volatility_7d_volume + 
                            eth_return_marketcap + eth_momentum_7d_marketcap + 
                            eth_volatility_7d_marketcap + 
                            eth_return_gas + eth_momentum_7d_gas + 
                            eth_volatility_7d_gas,
                     data = df_train_extended)

# Extract model statistics
model_stats <- glance(model_extended)

r2 <- sprintf("%.3f", model_stats$r.squared)
adj_r2 <- sprintf("%.3f", model_stats$adj.r.squared)
f_stat <- sprintf("%.2f", model_stats$statistic)


#Prepare nice output of significance
table3_df <- tidy(model_extended) %>%
  mutate(
    stars = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      p.value < 0.1 ~ ".",
      TRUE ~ ""
    ),
    Estimate_SE = paste0(
      sprintf("%.4f", estimate), stars, "\\(",
      sprintf("%.4f", std.error), ")"
    )
  ) %>%
  select(term, Estimate_SE)

#Renaming
pretty_names <- c(
  "(Intercept)" = "Intercept",
  "momentum_3d" = "Momentum (3d)",
  "momentum_7d" = "Momentum (7d)",
  "momentum_14d" = "Momentum (14d)",
  "return_lag1" = "Lagged Return (1d)",
  "return_lag2" = "Lagged Return (2d)",
  "volatility_7d" = "Volatility (7d)",
  "rsi_14" = "RSI (14)",
  "sma_diff" = "SMA Diff",
  "macd_val" = "MACD Value",
  "macd_hist" = "MACD Histogram",
  "atr_14" = "ATR (14)",
  "monday" = "Monday",
  "tuesday" = "Tuesday",
  "wednesday" = "Wednesday",
  "thursday" = "Thursday",
  "friday" = "Friday",
  "btc_return" = "BTC Return",
  "btc_momentum_7d" = "BTC Momentum (7d)",
  "btc_volatility_7d" = "BTC Volatility (7d)",
  "eth_return" = "ETH Return",
  "eth_momentum_7d" = "ETH Momentum (7d)",
  "eth_volatility_7d" = "ETH Volatility (7d)",
  "eth_return_volume" = "ETH Volume",
  "eth_momentum_7d_volume" = "ETH Momentum (7d) × Volume",
  "eth_volatility_7d_volume" = "ETH Volatility (7d) × Volume",
  "eth_return_marketcap" = "ETH Market Cap",
  "eth_momentum_7d_marketcap" = "ETH Momentum (7d) × Market Cap",
  "eth_volatility_7d_marketcap" = "ETH Volatility (7d) × Market Cap",
  "eth_return_gas" = "ETH Gas",
  "eth_momentum_7d_gas" = "ETH Momentum (7d) × Gas",
  "eth_volatility_7d_gas" = "ETH Volatility (7d) × Gas"
)

table3_df$term <- pretty_names[table3_df$term]

# Create kableExtra table
kbl(#"latex",
    table3_df,
    col.names = c("", "Target Return"),
    booktabs = TRUE,
    caption = "Extended Regression Model: Predicting LINK Returns with Crypto Features",
    align = "lr"
  ) %>%
  kable_styling(
    latex_options = c("hold_position", "striped")
  ) %>%
  footnote(
  general = paste0(
    "Significance levels: *** $p < 0.01$; ** $p < 0.05$; * $p < 0.1$.\\\\ ",
    "Model statistics: $R^2 = ", r2,
    "$, $R^2_{adj} = ", adj_r2,
    "$, F statistic = ", f_stat, "."
  ),
  general_title = "",
  threeparttable = TRUE,
  escape = FALSE  #allows math formatting 
)

```

Table 3 presents the output of our extended OLS regression model, where the dependent variable is the daily log return of LINK. This model includes not only LINK-specific momentum indicators but also technical indicators, calendar dummies, and a broad set of macro-crypto variables derived from Bitcoin (BTC) and Ethereum (ETH). The purpose of this model is to evaluate whether combining crypto-specific and cross-asset features can improve return predictability over the basic 7-day momentum model (as seen in Table 2). Several predictors emerge as statistically significant. The strongest within-asset signals are the one-day and two-day lagged LINK returns, both of which have positive and significant coefficients (0.0796 and 0.0920), indicating short-term positive autocorrelation. Interestingly, the coefficient for 3-day momentum is significantly negative, suggesting some evidence of short-term reversal over that horizon. In contrast, longer momentum terms (7-day and 14-day) are negative but not statistically significant.

From a cross-asset perspective, the results reveal that BTC returns are negatively associated with LINK returns (-1.0111), pointing to potential substitution effects or temporary decoupling between the two assets. This negative correlation seems economically reasonable, since major bull or bear runs in the dominant cryptocurreny BTC appeal traders to readjust portfolio composition, heavily impacting the prices of altcoins. Similarly, BTC volatility has a negative and significant impact, implying that increased uncertainty in BTC reduces returns for LINK. A similar pattern is observed for ETH returns, which also carry a negative and marginally significant coefficient (-1.0707). Notably, the interaction between ETH momentum and market cap is positive and significant, suggesting that when ETH trends upward in conjunction with growing market cap, it positively influences LINK performance. 

The overall model fit improves substantially compared to the single momentum specification: the \( R^2 \) increases to 0.342, and the adjusted \( R^2 \) to 0.331, indicating that over 33% of the variation of LINK returns is now explained. The model’s F-statistic (30.97) confirms the joint significance of the regressors. 

However, the extended OLS regression model considers all features equivalently, yielding poor interpretability. Furthermore, having equal weights is a drawback, because there might exist highly correlated features that sum up to an overweighted influence on the prediction. Similarly, many non-significant features are taken into account, leading to undesired high variance. A solution to these downsides are variable selection and regularization techniques, which we consider in the next section.

**LASSO Model**

To prevent overfitting and perform automatic variable selection, we extend our linear modeling approach using the Least Absolute Shrinkage and Selection Operator (LASSO). The LASSO adds a penalty term to the standard OLS loss function, shrinking some coefficient estimates toward zero. This results in a sparse model that may improve predictive performance, particularly when dealing with multiple correlated predictors. Furthermore, reducing the number of relevant features allows for a better interpretation of simulation results.

The LASSO estimator is defined as the solution to the following optimization problem:

\[
\hat{\beta}^{\text{LASSO}} = \arg \min_{\beta_0, \beta} \left\{ \sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} x_{ij} \beta_j \right)^2 + \lambda \sum_{j=1}^{p} |\beta_j| \right\}
\]

where:
\begin{itemize}
  \item \( y_i \) is the target variable (e.g., one-day-ahead return),
  \item \( x_{ij} \) are the predictor variables,
  \item \( \beta_j \) are the coefficients,
  \item \( \lambda \geq 0 \) is the tuning parameter controlling the strength of the penalty.
\end{itemize}

As \( \lambda \) increases, more coefficients are shrunk toward zero. For \( \lambda = 0 \), the solution coincides with OLS.

We use 10-fold cross-validation to select the optimal \( \lambda \) that minimizes the mean squared prediction error on held-out data.

```{r echo = FALSE, results = 'asis'}

# Create the design matrix and response
X <- model.matrix(target_return ~ 
                    momentum_3d + momentum_7d + momentum_14d + 
                    return_lag1 + return_lag2 + 
                    volatility_7d + rsi_14 + sma_diff + 
                    macd_val + macd_hist + atr_14 + 
                    monday + tuesday + wednesday + thursday + friday +
                    btc_return + btc_momentum_7d + btc_volatility_7d +
                    eth_return_volume + eth_momentum_7d_volume + 
                    eth_volatility_7d_volume +
                    eth_return_marketcap + eth_momentum_7d_marketcap + 
                    eth_volatility_7d_marketcap +
                    eth_return_gas + eth_momentum_7d_gas + eth_volatility_7d_gas,
                  data = df_train_extended)[, -1]  # remove intercept column
y <- df_train_extended$target_return

# Run cross-validated LASSO
set.seed(42)
cv_lasso <- cv.glmnet(X, y, alpha = 1, nfolds = 10)

# Best lambda output
best_lambda <- cv_lasso$lambda.min
cat(sprintf("**Optimal Lambda from Cross-Validation:** $\\lambda^* = %.6f$\n\n", best_lambda))

```

Given this optimal lambda, we now run the LASSO regression, including all variables from the previous linear regression:

```{r, echo = FALSE}

# Fit final LASSO model using best lambda
model_lasso <- glmnet(X, y, alpha = 1, lambda = best_lambda)

# Save resuts
coef_df <- as.matrix(coef(model_lasso))
non_zero <- coef_df[coef_df != 0, , drop = FALSE]

lasso_table <- data.frame(
  Predictor = rownames(non_zero),
  Coefficient = round(non_zero[, 1], 6),
  row.names = NULL
)

#define nice names
nice_names <- c(
  "(Intercept)" = "Intercept",
  "btc_return" = "BTC Daily Return",
  "eth_momentum_7d_volume" = "ETH 7-Day Volume Momentum"
)

# Apply renaming
lasso_table$Predictor <- dplyr::recode(lasso_table$Predictor, !!!nice_names)


# Output results
kable(lasso_table, format = "latex", booktabs = TRUE, 
      caption = "Non-Zero Coefficients from LASSO Regression",
      label = "tab:lasso_coeffs",
      align = c("l", "r")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

```

The LASSO regression identified two non-zero predictors for explaining LINK returns:

1. Bitcoin Daily Return (Coefficient: -0.9552): This variable has a large and negative coefficient, indicating that when BTC’s daily return increases by 1 unit (in our scaled units), the predicted return of our LINK-based trading strategy decreases by approximately 0.9552 units, all else equal. This suggests a strong inverse relationship between BTC movements and our strategy, potentially due to hedging behavior or negative spillovers, as we have already detailed in the discussion of Table 3.

2. ETH 7-Day Volume Momentum (Coefficient: 0.0019): This predictor captures short-term trends in ETH’s trading volume. The positive but small coefficient implies that higher recent momentum in ETH trading volume is weakly associated with increased LINK returns, possibly due to spillover effects from rising market activity in related tokens. 

3. Intercept (Coefficient: 0.0014): The intercept represents the model’s baseline prediction when all predictors are zero. Here, it suggests a small positive base return, though in practice this often has less interpretive value than the covariates.

Remarkably, the ETH 7-day volume momentum was not statistically significant in the extended OLS model. This points out a key strength of the LASSO technique. While p-values from the OLS model reflect only marginal significance, LASSO aims to minimize prediction error with a penalty that encourages sparsity, taking combined predictive contribution into account. Therefore, LASSO can identify relevant explanatory variables that are non-significant in their marginal influence and drop significant ones as well. We investigate whether reducing features is fruitful by providing a comprehensive backtesting analysis.

\newpage
## 5. Forecasting & Backtesting

**In-Sample testing**

To evaluate the performance of our predictive models, we begin by conducting in-sample (IS) testing. This involves fitting each model on a fixed training sample and evaluating how well the model explains historical variation in the data.

We assess in-sample performance using the following criteria:

\begin{itemize}
  \item \textbf{Mean Squared Error (MSE)}: Measures the average squared difference between predicted and actual returns.
  \[
  \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
  \]
  
  \item \textbf{Coefficient of Determination - Adjusted \( R^2 \)}: Indicates the proportion of variance explained by the model, adjusted for the number of predictors. It estimates the percentage of predictable variations in the dependent variable with respect to the explanatory variables.
  
  \[
  R_{\text{adj}}^2 = 1 - \frac{\text{RSS}/(n - p - 1)}{\text{TSS}/(n - 1)}
  \]

  \item \textbf{Directional Accuracy}: The fraction of times the predicted direction matches the actual direction of returns.
  \[
  \text{Accuracy} = \frac{1}{n} \sum_{i=1}^{n} \mathds{1} \left( \text{sign}(\hat{y}_i) = \text{sign}(y_i) \right)
  \]
\end{itemize}

Thereby, \(n\) denotes the respective sample size, \(p\) the number of predictors, RSS the residual sum of squares, TSS the total sum of squares, and \(\mathds{1}\) the indicator function. Hence, RSS is the sum of squared prediction errors, while TSS is the sum of squared differences between mean and predictions, which is proportional to the variance.

These metrics are computed for all three models:
\begin{enumerate}
  \item Benchmark (7-day momentum only),
  \item Extended linear model with multiple features,
  \item LASSO-regularized regression with automatic feature selection.
\end{enumerate}

```{r, echo = FALSE}
# Benchmark model (already estimated) 
model_benchmark <- lm(target_return ~ momentum_7d, data = df_train_extended)

# Predictions
df_train_extended <- df_train_extended %>%
  mutate(
    pred_benchmark = predict(model_benchmark),
    pred_extended = predict(model_extended),
    pred_lasso = as.numeric(predict(model_lasso, newx = X)),

    # For directional accuracy
    dir_true = sign(target_return),
    dir_benchmark = sign(pred_benchmark),
    dir_extended = sign(pred_extended),
    dir_lasso = sign(pred_lasso)
  )

# Evaluation metrics
mse <- function(pred, actual) mean((pred - actual)^2)
acc <- function(pred, actual) mean(sign(pred) == sign(actual))

# Manually calculate R2 for LASSO (not provided by glmnet)
rss_lasso <- sum((df_train_extended$pred_lasso - df_train_extended$target_return)^2)
tss_lasso <- sum((df_train_extended$target_return - mean(df_train_extended$target_return))^2)
r2_lasso <- 1 - rss_lasso / tss_lasso

#bring all in sample results together 
results_is <- tibble(
  Model = c("Benchmark", "Extended", "LASSO"),
  MSE = c(
    mse(df_train_extended$pred_benchmark, df_train_extended$target_return),
    mse(df_train_extended$pred_extended, df_train_extended$target_return),
    mse(df_train_extended$pred_lasso, df_train_extended$target_return)
  ),
  Directional_Accuracy = c(
    acc(df_train_extended$pred_benchmark, df_train_extended$target_return),
    acc(df_train_extended$pred_extended, df_train_extended$target_return),
    acc(df_train_extended$pred_lasso, df_train_extended$target_return)
  ),
  Adj_R2 = c(
    summary(model_benchmark)$adj.r.squared,
    summary(model_extended)$adj.r.squared,
    r2_lasso
  )
)

# Output IS results
results_is %>%
  mutate(across(where(is.numeric), \(x) round(x, digits = 4))) %>%
  mutate(Adj_R2 = sprintf("%.2f\\%%", Adj_R2 * 100)) %>% 
  kable("latex", booktabs = TRUE,
        caption = "In-Sample Performance of Benchmark, Extended, and LASSO Models",
        label = "tab:in_sample_perf",
        align = "lrrr",
        escape = FALSE,
        col.names = c("Model", "MSE", "Directional Accuracy", "$\\mathrm{R}^2_{\\mathrm{adj}}$")) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

```


Table 5 shows that the Extended and LASSO models have superior in-sample performance compared to the Benchmark model. The Benchmark model has the highest mean squared error (MSE = 0.0053) and the lowest directional accuracy (0.5051). This indicates poor predictive precision and a limited ability to correctly predict the direction of change. Furthermore, its negative adjusted \(R^2\) (-0.05%) suggests that it fails to explain the variation in the dependent variable and performs worse than a simple mean model.

Compared with the Benchmark model, the Extended and Lasso models demonstrate substantially improved performance with notably lower MSEs (0.0035 and 0.0036, respectively) and significantly higher directional accuracy (0.7110 and 0.7142, respectively). Their adjusted \(R^2\) values (33.10% for the Extended model and 32.29% for the Lasso model) suggest that both models meaningfully explain the variance in the data, though the Extended model has a slight advantage. These results confirm that the Extended and Lasso models offer stronger in-sample predictive capabilities than the Benchmark model.

**Out-of-sample testing:**

After performing the in-sample analysis, we now test our models out-of-sample (OOS) on the test data set: 

```{r, echo = FALSE}

#create the required matrix for LASSO based on the test data 
X_test <- model.matrix(target_return ~ 
  momentum_3d + momentum_7d + momentum_14d + 
  return_lag1 + return_lag2 + 
  volatility_7d + rsi_14 + sma_diff + 
  macd_val + macd_hist + atr_14 + 
  monday + tuesday + wednesday + thursday + friday +
  btc_return + btc_momentum_7d + btc_volatility_7d +
  eth_return_volume + eth_momentum_7d_volume + 
  eth_volatility_7d_volume +
  eth_return_marketcap + eth_momentum_7d_marketcap + 
  eth_volatility_7d_marketcap +
  eth_return_gas + eth_momentum_7d_gas + eth_volatility_7d_gas,
  data = df_test_extended)[, -1] 


df_test_extended <- df_test_extended %>%
  mutate(
    pred_benchmark = predict(model_benchmark, newdata = df_test_extended),
    pred_extended  = predict(model_extended, newdata = df_test_extended),
    pred_lasso     = as.numeric(predict(model_lasso, newx = X_test)),

    # Directional accuracy
    dir_true       = sign(target_return),
    dir_benchmark  = sign(pred_benchmark),
    dir_extended   = sign(pred_extended),
    dir_lasso      = sign(pred_lasso)
  )

mean_train_return <- mean(df_train_extended$target_return, na.rm = TRUE)

# Define R²_OS function
r2_os <- function(actual, predicted, mean_train) {
  ss_res <- sum((actual - predicted)^2, na.rm = TRUE)
  ss_base <- sum((actual - mean_train)^2, na.rm = TRUE)
  1 - ss_res / ss_base
}

#bring all OOS results together into one table 
results_oos <- tibble(
  Model = c("Benchmark", "Extended", "Lasso"),
  MSE = c(
    mse(df_test_extended$pred_benchmark, df_test_extended$target_return),
    mse(df_test_extended$pred_extended, df_test_extended$target_return),
    mse(df_test_extended$pred_lasso, df_test_extended$target_return)
  ),
  Directional_Accuracy = c(
    acc(df_test_extended$pred_benchmark, df_test_extended$target_return),
    acc(df_test_extended$pred_extended, df_test_extended$target_return),
    acc(df_test_extended$pred_lasso, df_test_extended$target_return)
  )
)

# Add R2_OS column to results
results_oos <- results_oos %>%
  mutate(
    R2_OS = c(
      r2_os(df_test_extended$target_return, df_test_extended$pred_benchmark, mean_train_return),
      r2_os(df_test_extended$target_return, df_test_extended$pred_extended, mean_train_return),
      r2_os(df_test_extended$target_return, df_test_extended$pred_lasso, mean_train_return)
    )
  )

#results_oos

#show results nicely in a latex table for the knitted file 
results_oos %>%
  mutate(R2_OS = sprintf("%.2f\\%%", R2_OS * 100)) %>% 
  kable(format = "latex", digits = 4, caption = "Out-of-Sample Model Evaluation",
        booktabs = TRUE, 
        align = "lrrr",
        escape = FALSE,
        col.names = c("Model", "MSE", "Directional Accuracy", "$\\mathrm{R}^2_{\\mathrm{OOS}}$")) %>%
  kable_styling(latex_options = c("hold_position", "striped"))

```


The benchmark model fails to generalize out-of-sample (\( R^2_{\text{OOS}} \) = 0), confirming the weak predictive power of raw 7-day momentum. In contrast, the LASSO model improves out-of-sample accuracy substantially (\( R^2_{\text{OOS}} \) = 0.34), likely due to its ability to regularize noise and select relevant predictors.

To evaluate the trading performance of our predictive models beyond return forecasting, we implement a simple In-and-Out (I/O) strategy. This rule-based strategy enters the market ("IN") only when the model predicts strong positive returns — i.e., when the predicted value exceeds the 75th percentile of the respective model’s prediction distribution. Otherwise, the model takes the money out of the market ("OUT").

**Signal Construction:**

We construct separate trading signals for:

\begin{itemize}
  \item the Benchmark model (7-day momentum),
  \item the Extended Linear Regression model,
  \item the LASSO model, and
  \item the actual target returns (for reference).
\end{itemize}

The procedure:

\begin{itemize}
  \item 1 (enter position) if the predicted return exceeds the threshold
  \item 0 (stay out) otherwise
\end{itemize}


This setup computes the daily strategy returns by multiplying the lagged signal with the actual log return.
Additionally, we estimate the trading costs by applying a fixed fee per position change to simulate realistic trading costs. For the trading costs we consider the average Ethereum gas price per day and multiply it by 60,000, which roughly coincides with the factor for ERC-20 token transfer on the Ethereum blockchain.

This approach emphasizes selective participation in the market based on the model's confidence and allows us to assess whether models can not only predict returns but also generate economically meaningful signals.

```{r lasso_actvspred_plot, fig.cap = "Actual vs Predicted Target Returns (LASSO)", fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE}
# Implementation of an In-and-Out trading strategy

# compute 25% and 75% quantiles for signal derivation
qtiles_test_target <- quantile(df_train_extended$target_return, probs = c(0.25, 0.75), na.rm = TRUE)
qtiles_test_benchmark <- quantile(df_train_extended$pred_benchmark, probs = c(0.25, 0.75), na.rm = TRUE)
qtiles_test_extended <- quantile(df_train_extended$pred_extended, probs = c(0.25, 0.75), na.rm = TRUE)
qtiles_test_lasso <- quantile(df_train_extended$pred_lasso, probs = c(0.25, 0.75), na.rm = TRUE)


# append trading signals (IN if 75% quantile is exceeded)
df_test_extended <- df_test_extended %>% 
  mutate(
    signal_target = case_when(
      target_return > qtiles_test_target[2] ~ 1,
      target_return <= qtiles_test_target[2] ~ 0,
      TRUE ~ 0
    ),
    signal_benchmark = case_when(
      pred_benchmark > qtiles_test_benchmark[2] ~ 1,
      pred_benchmark <= qtiles_test_benchmark[2] ~ 0,
      TRUE ~ 0
    ),
    signal_extended = case_when(
      pred_extended > qtiles_test_extended[2] ~ 1,
      pred_extended <= qtiles_test_extended[2] ~ 0,
      TRUE ~ 0
    ),
    signal_lasso = case_when(
      pred_lasso > qtiles_test_lasso[2] ~ 1,
      pred_lasso <= qtiles_test_lasso[2] ~ 0,
      TRUE ~ 0
    )
  )


df_test_extended <- df_test_extended %>% 
  mutate(
    benchmark_return = lag(signal_benchmark)*log_return,
    extended_return = lag(signal_extended)*log_return,
    lasso_return = lag(signal_lasso)*log_return,
    benchmark_fee_flag = abs(signal_benchmark-lead(signal_benchmark)),
    extended_fee_flag = abs(signal_extended-lead(signal_extended)),
    lasso_fee_flag = abs(signal_lasso-lead(signal_lasso))
  )

df_test_extended <- df_test_extended %>% 
  drop_na() %>%
  mutate(
    cum_return = cumsum(log_return),
    cum_benchmark_return = cumsum(benchmark_return),
    cum_extended_return = cumsum(extended_return),
    cum_lasso_return = cumsum(lasso_return),
    cum_fees_benchmark = cumsum(fees_dollar*benchmark_fee_flag),
    cum_fees_extended = cumsum(fees_dollar*extended_fee_flag),
    cum_fees_lasso = cumsum(fees_dollar*lasso_fee_flag)
  )

threshold <- qtiles_test_lasso[2]


# Create a data frame with rectangles and labels for the fill legend
rects <- data.frame(
  xmin = c(-Inf, 0),
  xmax = c(0, Inf),
  ymin = c(threshold, threshold),
  ymax = c(Inf, Inf),
  label = c("False Positives", "Correct")
)

# Plot predicted returns vs actual returns
plot_1_inout <- ggplot(df_test_extended, aes(x = target_return, y = pred_lasso)) +
  # Background rectangles with fill mapped to "label" for legend:
  geom_rect(data = rects,
            aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = label),
            alpha = 0.5, inherit.aes = FALSE) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_abline(aes(intercept = qtiles_test_lasso[2], slope = 0, color = "75th percentile")) +
  geom_abline(aes(intercept = 0, slope = 1, color = "Perfect fit"), linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Target Returns (LASSO)",
    x = "Actual Target Return",
    y = "Predicted Target Return",
    color = "Line",
    fill = "Region"
  ) +
  scale_color_manual(values = c(
    "75th percentile" = "blue",
    "Perfect fit" = "red"
  )) +
  scale_fill_manual(values = c(
    "Correct" = "honeydew",
    "False Positives" = "mistyrose"
  )) +
  theme_minimal()


# Plot cumulative returns of trading strategy on test data
plot_2_inout <-  ggplot(df_test_extended, aes(x = date)) +
  geom_line(aes(y = exp(cum_return), color = "Buy&Hold")) +
  geom_line(aes(y = exp(cum_benchmark_return), color = "7-Day Momentum")) +
  geom_line(aes(y = exp(cum_extended_return), color = "Linear Regression")) +
  geom_line(aes(y = exp(cum_lasso_return), color = "LASSO")) +
  labs(title = "Cumulative Returns: LASSO vs 7-Day Momentum vs LR",
       x = "Date", y = "Cumulative Return") +
  scale_color_manual(values = c("Buy&Hold" = "black",
                                "7-Day Momentum" = "blue",
                                "Linear Regression" = "green",
                                "LASSO" = "darkred"
                                )) +
  theme_minimal()


# Plot cumulative trading fees
plot_3_inout <- ggplot(df_test_extended, aes(x = date)) +
  geom_line(aes(y = (cum_fees_benchmark), color = "7-Day Momentum")) +
  geom_line(aes(y = (cum_fees_extended), color = "Linear Regression")) +
  geom_line(aes(y = (cum_fees_lasso), color = "LASSO")) +
  labs(title = "Cumulative Fees: LASSO vs 7-Day Momentum vs LR",
       x = "Date", y = "Cumulative Fees (USD)") +
  scale_color_manual(values = c("Buy&Hold" = "black",
                                "7-Day Momentum" = "blue",
                                "Linear Regression" = "green",
                                "LASSO" = "darkred"
                                )) +
  theme_minimal()



plot_1_inout
```

Figure 3 visualizes the relationship between actual and predicted one-day-ahead returns from the LASSO regression model. Each point represents an observation in the test set, with the x-axis showing the realized return and the y-axis the model’s predicted return. The dashed red line indicates the 45° line of perfect predictions, while the blue horizontal line marks the 75th percentile of predicted returns.

We observe a moderate clustering of points around the diagonal, suggesting that the LASSO model captures some predictive structure in the return dynamics, particularly for returns near zero. However, deviations from the red line highlight prediction errors, especially in the tails.

The green region denotes instances where the predicted and actual returns have the same sign — i.e., the model correctly forecasts the return direction. These cases reflect successful directional predictions, which are critical for long/short trading strategies. In contrast, the red-shaded area highlights false positives, where the model incorrectly predicts a positive return, but the actual return is negative.

While the spread around the diagonal indicates that exact return magnitudes are not always accurately predicted, the high density in the green region supports the model’s strong directional accuracy (see Table 6). This suggests that the LASSO model is well-suited for sign-based trading rules, even if its point predictions are noisy.


```{r lasso_cum_plot, fig.cap = "Cumulative Performance of Trading Strategies (Log Returns and Fees)", fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE}
#show the other two plots separately 

grid.arrange(plot_2_inout, plot_3_inout, ncol = 1, nrow = 2)
```


The **top panel** of Figure 4 compares the cumulative returns of four strategies:

\begin{itemize}
  \item LASSO model (dark red) achieves the highest return, significantly outperforming all others.
  \item Linear Regression (green) performs closely behind LASSO.
  \item The 7-Day Momentum (blue) lags far behind, reflecting its weak signal quality.
  \item Buy-and-Hold (black) delivers minimal returns with no active decision-making.
\end{itemize}


The **bottom panel** shows cumulative trading fees incurred due to signal changes:

\begin{itemize}
  \item Both LASSO and Linear Regression generate more trades and hence higher fees.
  \item Despite these higher transaction costs, their net performance (gross return - fees) still can be superior if the initial investment is chosen high enough.
  \item The 7-Day Momentum strategy results in fewer position switches and lower fees but offers little economic value due to poor returns.
\end{itemize}


Overall, the LASSO model demonstrates superior performance, not only in terms of return predictability but also as a trading signal generator. In practice, one must account for transaction costs as well.

**Limitations**

However, the model does face certain limitations when transitioning to real-world application. One key challenge lies in the assumption of perfect trade execution at the daily closing price. In highly volatile markets, the actual execution price often deviates from the expected one due to slippage, which can impact strategy performance. This effect may be further intensified in periods of low liquidity, where execution latency and order book depth become critical factors.

Additionally, the LASSO-based approach, by design, captures only linear relationships between LINK returns and the selected features. While this promotes interpretability and robustness, it also limits the model’s ability to reflect the nonlinear dynamics that frequently characterize cryptocurrency markets. As a result, certain predictive patterns may remain unexplored.

These limitations, however, open promising avenues for further enhancement. Future iterations of the strategy could integrate execution-aware trading algorithms and explore nonlinear modeling techniques, such as deep neural networks or tree-based ensembles, to better capture complex market behavior. By addressing these challenges, the strategy could evolve into a more powerful and realistic tool for active crypto asset management.


```{r, echo = FALSE}
# 1) Compute daily strategy returns & cumulative log-returns
# df_test_extended <- df_test_extended %>%
#   mutate(
#     # daily strategy log-returns = signal × next-day log return
#     ret_benchmark      = dir_benchmark  * target_return,
#     ret_extended       = dir_extended   * target_return,
#     ret_lasso          = dir_lasso      * target_return,
#     # cumulative log returns
#     cum_ret_benchmark  = cumsum(coalesce(ret_benchmark,  0)),
#     cum_ret_extended   = cumsum(coalesce(ret_extended,   0)),
#     cum_ret_lasso      = cumsum(coalesce(ret_lasso,      0)),
#     cum_ret_bh         = cumsum(coalesce(log_return,      0))
#   )
# 
# # 2) Pivot to long format
# df_plot <- df_test_extended %>%
#   select(date,
#          "Buy & Hold"      = cum_ret_bh,
#         "Benchmark"         = cum_ret_benchmark,
#          "Extended Model"    = cum_ret_extended,
#         "Lasso Model"       = cum_ret_lasso
#   ) %>%
#   pivot_longer(-date, names_to = "Strategy", values_to = "Cumulative_Log_Return")
# 
# # 3) Plot
# ggplot(df_plot, aes(x = date, y = Cumulative_Log_Return, color = Strategy)) +
#   geom_line(linewidth = 1) +
#   scale_color_manual(
#     values = c(
#       "Benchmark" = "blue",   # Blue
#       "Buy & Hold"     = "black",
#       "Lasso Model"          = "darkred",
#       "Extended Model" = "green")
#     ) +
#   labs(
#     title = "Cumulative Log Returns: Buy-&-Hold vs. Benchmark, Extended & Lasso",
#     x     = "Date",
#     y     = "Cumulative Log Return",
#     color = NULL
#   ) +
#   theme_minimal()
```


```{r, echo = FALSE}

#COMMENTED OUT BECAUSE OF LONG RUNNING TIME

#define a function to run the rolling out-of-sample lasso regression
# run_rolling_lasso <- function(df, y_var, window_size = 500, x_vars = NULL) {
#   # Drop rows where the target variable is NA
#   df <- df %>% filter(!is.na(.data[[y_var]]))
#   
#   # Automatically detect predictors if not provided
#   if (is.null(x_vars)) {
#     predictors <- setdiff(names(df), c("date", y_var))
#   } else {
#     predictors <- x_vars
#   }
#   
#   # Storage for predictions
#   predictions <- rep(NA, nrow(df))
# 
#   # Rolling window loop
#   for (i in seq(window_size + 1, nrow(df))) {
#     # Get training and test data
#     train_data <- df[(i - window_size):(i - 1), ]
#     test_data <- df[i, ]
# 
#     # Extract X and y matrices
#     x_train <- as.matrix(train_data[, predictors])
#     y_train <- train_data[[y_var]]
# 
#     x_test <- as.matrix(test_data[, predictors])
# 
#     # Fit LASSO model
#     cv_fit <- cv.glmnet(x_train, y_train, alpha = 1)
#     best_lambda <- cv_fit$lambda.min
#     # Refit LASSO model using best lambda
#     model <- glmnet(x_train, y_train, alpha = 1, lambda = best_lambda)
# 
#    # Predict for one-step ahead
#     predictions[i] <- predict(model, newx = x_test)
#   }
# 
#   # Return tibble with actual vs predicted
#   tibble(
#     date = df$date,
#     actual = df[[y_var]],
#     predicted = predictions
#   )
# }
# 
# x_vars <- colnames(df_extended)[!(colnames(df_extended) %in% c("date", "target_return"))]
# 
# # Keep only numeric predictors
# x_vars_numeric <- x_vars[sapply(df_extended[, x_vars], is.numeric)]
# 
# # Filter for complete cases in x_vars_numeric + target_return
# df_clean_rolling <- df_extended %>%
#   dplyr::select(date, target_return, all_of(x_vars_numeric)) %>%
#   filter(complete.cases(.))
# 
# #For each out-of-sample prediction, the model is trained on the previous 500 observations
# results_rolling <- run_rolling_lasso(
#   df = df_clean_rolling,
#   y_var = "target_return",
#   window_size = 500,
#   x_vars = colnames(df_clean_rolling)[!(colnames(df_clean_rolling) %in% c("date", "target_return"))]
# )

```



```{r, echo = FALSE}
# # Make sure 'results' has no NAs in actual or predicted
# results_clean_rolling <- results_rolling %>% filter(!is.na(actual), !is.na(predicted))
# 
# # Compute performance metrics
# r_squared_rolling <- cor(results_clean_rolling$actual, results_clean_rolling$predicted)^2
# mse_rolling <- mean((results_clean_rolling$actual - results_clean_rolling$predicted)^2)
# directional_accuracy_rolling <- mean(sign(results_clean_rolling$actual) == sign(results_clean_rolling$predicted))
# 
# # Compute Sharpe Ratios (daily returns assumed)
# sharpe_ratio_actual_rolling <- mean(results_clean_rolling$actual) / sd(results_clean_rolling$actual) * sqrt(252)
# sharpe_ratio_pred_rolling <- mean(results_clean_rolling$predicted) / sd(results_clean_rolling$predicted) * sqrt(252)
# 
# # Print metrics
# performance_metrics_rolling <- tibble(
#   `R-squared` = r_squared_rolling,
#   `MSE` = mse_rolling,
#   `Directional Accuracy` = directional_accuracy_rolling,
#   `Sharpe Ratio (Actual)` = sharpe_ratio_actual_rolling,
#   `Sharpe Ratio (Predicted)` = sharpe_ratio_pred_rolling
# )
# 
# performance_metrics_rolling %>%
#   kable("latex", booktabs = TRUE, digits = 4,
#         caption = "Table 5: Out-of-Sample Performance Metrics of LASSO Model") %>%
#   kable_styling(latex_options = c("striped", "hold_position", "scale_down")) %>%
#   row_spec(0, bold = TRUE)


```

\newpage
## 6. Conclusion

Our results demonstrate that short-term predictability in the crypto space is possible using a structured, data-driven approach. We developed and backtested a daily trading strategy for LINK that issued “in” or “out” signals based on predicted next-day returns. The strategy enters the market only when the forecasted return exceeds the model-specific 75th percentile, thereby focusing on high-confidence signals. 
While a simple 7-day momentum signal proved insufficient, we enhanced performance by incorporating a broad feature set: momentum signals, volatility indicators, cross-asset spillovers, technical indicators, and calendar effects. Our final model uses Lasso regression to select only the most predictive variables and prevent overfitting. The Lasso model achieves the highest out-of-sample \( R^2 \) (33.6%) and directional accuracy (73.6%), outperforming both buy-and-hold and naïve momentum strategies.
However, we made simplifying assumptions, such as perfect trade execution at the daily close price, which limits the model’s applicability in real-world settings. In practice, slippage and latency can significantly impact returns, especially in volatile or illiquid markets. Additionally, the model captures only linear relationships, potentially missing complex market dynamics. These limitations emphasize opportunities for further enhancement, such as incorporating deep neural networks to better model nonlinear behavior.

\newpage
## A Appendix

**14-Day Relative Strength Index (RSI)**

The RSI is an index that takes values between 0 and 100. Its computation is derived from the relative strength
\[ RS = \frac{\text{SMMA}(U,n)}{\text{SMMA}(D,n)}\]
\[\Rightarrow RSI = 100 - \frac{100}{1-\text{RS}}\]

SMMA denotes the smoothed or modified moving average, which is an exponentially weighted average with weighting factor \(1/n\). Moreover,
\[U = \text{close}_{t-n} - \text{close}_{t}\]
denoting an upward change and
\[D = \text{close}_{t} - \text{close}_{t-n}\]
a downward change respectively.

In our model \(n\) is set to 14. RSI is often associated with overbought and oversold conditions.


**Moving Average Convergence/Divergence (MACD)**

The MACD value is computed under the inclusion of exponentially weighted moving averages (EWMA). EWMA assigns exponentially decreasing weights to all past values. The speed of decline depends on the time constant (which we denote in the index) that indicates the number of time steps until the weighting factor reaches \(63.2\%\) of the initial value.
MACD then is constructed by:
\[ \text{MACD} = \text{EWMA}_9(\text{EWMA}_{12}-\text{EWMA}_{26}), \]
where \(\text{EWMA}_n(x)\) denotes the moving average of \(x\) with a time constant of \(n\).

From an economic perspective, the MACD value can reveal changes in the trend of a financial asset, since it captures differences between averages of long- and short-term periods. This makes it a strong predictor, especially for assets with infrequent trend changes.

**Simple Moving Average (SMA) Difference**

By the SMA Difference we denote the difference between a simple moving average of the close prices of the last 7 days and the last 14 days. Let \(\text{SMA}_n\) be the average close price of the last n days. Then
\[\text{SMA}_{Diff} = \text{SMA}_{7}-\text{SMA}_{14}\]

The SMA Difference indicates short-term momentum relative to the longer-term trend. A positive value suggests recent prices are rising faster than the broader trend, potentially signaling bullish sentiment, while a negative value may indicate emerging bearish pressure.

**Average True Range (ATR)**

ATR measures market volatility by averaging the true range over a specified period. Let \(\text{TR}_t = \max\{ \text{High}_t - \text{Low}_t, |\text{High}_t - \text{Close}_{t-1}|, |\text{Low}_t - \text{Close}_{t-1}| \}\) be the true range on day \(t\). Then the 14-day ATR is defined as:
\[\text{ATR}_{14} = \frac{1}{14} \sum_{i=0}^{13} \text{TR}_{t-i}\]

The ATR reflects how much an asset typically moves in a day, with higher values indicating greater volatility. It does not indicate price direction but helps assessing risk and adjusting position sizes or stop-loss levels accordingly.





